---
title: "Predicting the brexit vote"
author: ""
date: ""
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Data

- In this exercise, we will work on a classification task of Brexit referendum vote
- The data is originally from British Election Study Online Panel
  - codebook: https://www.britishelectionstudy.com/wp-content/uploads/2020/05/Bes_wave19Documentation_V2.pdf
- The outcome is `LeaveVote` (1: Leave, 0: Remain)

## Libraries

- We will use the following packages

```{r}
library(tidyverse)
library(caret)
library(glmnet)
```

## Load data

We sub-sample the data. Full data takes too much time to estimate for the class... (Feel free to run full sample after the class)

```{r}
set.seed(20200813)
df_brexit <- read_csv("data/data_bes.csv.gz") %>%
  sample_n(3000) # sampling data so (sample_frac() for percentual sampling)
```


## Data preparation

- We will carry out:
  - make `LeaveVote` factor variable
  - test train split
  - preprocess


```{r}
df_brexit <- df_brexit %>%
    mutate(LeaveVote = factor(LeaveVote))
```

### Train-test split

```{r}
train_idx <- createDataPartition(df_brexit$LeaveVote, p = .7, list = F) 

df_train <- df_brexit %>% slice(train_idx)
df_test <- df_brexit %>% slice(-train_idx)
```

### Preprocess

```{r}
prep <- preProcess(df_train %>% select(-LeaveVote), method = c("center", "scale"))
prep

df_train_preped <- predict(prep, df_train)
df_test_preped <- predict(prep, df_test)

```

## Model formulas

There are four logistic regression models  in the manuscript (Table 2).

1. Sociodemographics
2. Identity
3. Anti-elite
4. Attitudes

The following line of codes will generate the each model. 

```{r}
fm_socdem <- formula("LeaveVote ~ gender + age + edlevel + hhincome + econPersonalRetro1")
fm_identity <- formula("LeaveVote ~ gender + age + edlevel + hhincome + 
                        EuropeanIdentity + EnglishIdentity + BritishIdentity")
fm_antielite <- formula("LeaveVote ~ gender + age + edlevel + hhincome + 
              PolMistrust + GovDisapproval + PopulismScale + 
              ConVote + LabVote + LibVote + SNPPCVote + UKIP")
fm_attitudes <- formula("LeaveVote ~ gender + age + edlevel + hhincome + euUKNotRich + 
              euNotPreventWar + FreeTradeBad + euParlOverRide1 + euUndermineIdentity1 + 
              lessEUmigrants + effectsEUTrade1 + effectsEUImmigrationLower")
fm_all <- formula("LeaveVote ~ .")

# formula objects are helpful for switching out formulas in models
```

You can use these formulas in a way like:

```{r eval = F}
# for model
glm(fm_socdem, data = df_train_preped, family = "binomial")
# for data extraction
model.matrix(fm_socdem, data = df_train_preped) %>% head()

```

## Logistic regression

Run a few models, and evaluate them. Which one has the better predictive performance?

```{r}
mod_socdem <- glm(fm_socdem, data = df_train_preped, family = "binomial")


# pred_train <- as.integer(predict(mod_socdem, newdata = df_train_preped) > .5) %>% factor()
# 
# confusionMatrix(df_train_preped$LeaveVote, pred_train, mode = "everything")


pred_test <- as.integer(predict(mod_socdem, newdata = df_test_preped) > .5) %>% factor()

# confusionMatrix(df_test_preped$LeaveVote, pred_test, mode = "prec_recall") # precision & recall only

confusionMatrix(df_test_preped$LeaveVote, pred_test, mode = "everything")


logit_performance <- function(fm){
  mod <- glm(fm, data = df_train_preped, family = "binomial")
  pred_test <- as.integer(predict(mod, newdata = df_test_preped) > .5) %>% factor()
  confusionMatrix(df_test_preped$LeaveVote, pred_test, 
                  positive = "1",                     # change positive category to "voting for the referendum"
                  mode = "everything") %>% print()
}

cat("\nFull Model\n")
logit_performance(fm_all)

cat("\nAnti Elite\n")
logit_performance(fm_antielite)

cat("\nIdentity\n")
logit_performance(fm_identity)

cat("\nSocial Demographics\n")
logit_performance(fm_socdem)

cat("\nAttitudes\n")
logit_performance(fm_attitudes)
# attitudes seem to be the strongest predictor
```

## Linear SVM

- Train a linear SVM model, check the predictive performance. How does it compare to the logistic regression?

```{r}
ctrl <- trainControl(method = "repeatedcv", repeats = 3, number = 5)

mod_svmlinear <- train(fm_all, 
                       method = "svmLinear",    # see caret website for a model overview: http://topepo.github.io/caret/available-models.html
                       data = df_train_preped, 
                       trControl = ctrl,
                       tuneGrid = data.frame(C = c(0.25, 1, 5, 10)))

mod_svmlinear 

pred_test <- predict(mod_svmlinear, newdata = df_test_preped)

confusionMatrix(df_test_preped$LeaveVote, pred_test,
                positive = "1",
                mode = "everything")


logit_performance(fm_all)
```


## Polynomial SVM and Radial SVM

- Train non-linear SVM. How is the performance? Any improvement?

```{r cache=T}
mod_svmpoly<- train(fm_all, 
                       method = "svmPoly",    # see caret website for a model overview: http://topepo.github.io/caret/available-models.html
                       data = df_train_preped, 
                       trControl = ctrl)

mod_svmpoly 

pred_test <- predict(mod_svmpoly, newdata = df_test_preped)

confusionMatrix(df_test_preped$LeaveVote, pred_test,
                positive = "1",
                mode = "everything")


mod_svmradial<- train(fm_all, 
                       method = "svmRadial",    # see caret website for a model overview: http://topepo.github.io/caret/available-models.html
                       data = df_train_preped, 
                       trControl = ctrl)

mod_svmradial 

pred_test <- predict(mod_svmradial, newdata = df_test_preped)

confusionMatrix(df_test_preped$LeaveVote, pred_test,
                positive = "1",
                mode = "everything")


```


## (Optional) Logistic regression with LASSO

- `glmnet` can run a Logistic model with L1 penalty (LASSO). 
- Try a "full" model combining all inputs.
  - Which inupts survived?

```{r}
mat_train_x <- df_train_preped %>% select(-LeaveVote) %>% as.matrix() #glmnet requires a matrix as input
mat_test_x <- df_test_preped %>% select(-LeaveVote) %>% as.matrix() 

model_lasso <- cv.glmnet(mat_train_x, 
                         df_train_preped$LeaveVote, #output variable
                         alpha = 1, # 1 for lasso, if alpha = 0 this runs ridge regression
                         family = "binomial") # family argument is required for glm functions

coef(model_lasso) # glmnet chooses final lambda (and therefore nr of variables) based on increase in RMSE against best model
plot(model_lasso)
plot(model_lasso$glmnet.fit, xvar = "lambda")
plotmo::plot_glmnet(model_lasso$glmnet.fit, xvar = "lambda")

pred_test <- as.integer(predict(model_lasso, newx = mat_test_x) > 0) %>% factor()

confusionMatrix(df_test_preped$LeaveVote, pred_test,
                positive = "1",
                mode = "everything")


```


### Reporting ROC

- `twoClassSummary` provides ROC
  - setting up the data to send to this function is quite tricky
  - it needs 4 column data frame with the structure below
- Calculating ROC requires methods that report the probability of class 

```{r}
calc_roc_logit <- function(fm, print_dat = F){
  print(fm)
  levels(df_test_preped$LeaveVote) <- c("class0", "class1")
  mod <- glm(fm, data = df_train_preped, family = 'binomial')
  prob1 <- predict(mod, newdata = df_test_preped, type = "response")
  prob0 <- 1 - prob1
  pred_test <- as.integer(prob1 > .5) %>% factor(labels = c("class0", "class1"))
  dat <- data.frame(obs = df_test_preped$LeaveVote, pred = pred_test, "class1" = prob1, 
                    'class0' = prob0)
  if(print_dat) print(head(dat))
  print(twoClassSummary(dat, lev = levels(pred_test)))
}
calc_roc_logit(fm_socdem, print_dat = T)
  
```
